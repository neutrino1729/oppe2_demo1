name: MLOps Fraud Detection Pipeline

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

permissions:
  contents: read
  pull-requests: write

jobs:
  data-validation-and-training:
    name: Data Validation & Model Training
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Authenticate to Google Cloud
      env:
        GCP_CREDENTIALS_B64: ${{ secrets.GCP_CREDENTIALS_B64 }}
      run: |
        echo "$GCP_CREDENTIALS_B64" | base64 -d > gcp-key.json
        echo "GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-key.json" >> $GITHUB_ENV
        python3 -c "import json; json.load(open('gcp-key.json'))" && echo "âœ“ Valid JSON"
    
    - name: Install Google Cloud SDK
      run: |
        echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
        curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
        sudo apt-get update && sudo apt-get install -y google-cloud-cli
    
    - name: Configure DVC and Pull Data
      run: |
        gcloud auth activate-service-account --key-file=gcp-key.json
        gcloud config set project theta-index-472515-d8
        dvc remote modify gcsremote credentialpath $(pwd)/gcp-key.json
        dvc pull -v
    
    - name: Run Data Validation Tests
      run: |
        echo "## ðŸ§ª Data Validation Tests" >> report.md
        pytest tests/test_data_validation.py -v >> report.md 2>&1 || true
    
    - name: Check for Data Poisoning
      id: poison_check
      run: |
        echo "" >> report.md
        echo "## ðŸ›¡ï¸ Data Poisoning Check" >> report.md
        python src/check_poisoning.py --data-path data/transactions.csv >> report.md
        SUSPICIOUS_COUNT=$(grep "Suspicious labels found:" report.md | tail -1 | awk '{print $4}' | tr -d ',' || echo "0")
        echo "count=$SUSPICIOUS_COUNT" >> "$GITHUB_OUTPUT"
    
    - name: Validate Data Quality
      run: |
        SUSPICIOUS_COUNT="${{ steps.poison_check.outputs.count }}"
        if [ -z "$SUSPICIOUS_COUNT" ]; then SUSPICIOUS_COUNT=0; fi
        if [ "$SUSPICIOUS_COUNT" -gt 1000 ]; then
          echo "âŒ Too many suspicious labels. Aborting."
          exit 1
        fi
        echo "âœ… Data quality check passed"
    
    - name: Setup Feast Feature Store (CI Mode)
      run: |
        echo "ðŸ”§ Setting up Feast for CI environment..."
        cd feature_repo
        
        # Run CI setup script
        python setup_feast_ci.py
        
        # Apply Feast features (will create fresh registry)
        feast apply
        
        cd ..
        echo "âœ… Feast configured successfully"
    
    - name: Run Model Training (without Feast)
      env:
        CI: true
        SKIP_FEAST: true
      run: |
        echo "" >> report.md
        echo "## ðŸš€ Model Training" >> report.md
        echo "â„¹ï¸  Training without Feast in CI (using direct CSV)" >> report.md
        
        # Create simplified training script for CI
        python << 'PYTHON_EOF'
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
import joblib
import os
import json

print("Training model in CI mode...")

# Load data directly
df = pd.read_csv("data/transactions.csv")

# Prepare features
columns_to_drop = ['Class', 'Time']
if 'location' in df.columns:
    columns_to_drop.append('location')

X = df.drop(columns=columns_to_drop, errors='ignore')
y = df['Class']

# Train-test split
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Train model
params = {
    'class_weight': 'balanced',
    'max_depth': 5,
    'min_samples_split': 100,
    'min_samples_leaf': 50,
    'random_state': 42
}

model = DecisionTreeClassifier(**params)
model.fit(X_train, y_train)

# Evaluate
f1 = f1_score(y_val, model.predict(X_val))
print(f"F1-Score: {f1:.4f}")

# Save artifacts
os.makedirs("artifacts", exist_ok=True)
joblib.dump(model, "artifacts/model.pkl")

with open("artifacts/params.json", "w") as f:
    json.dump(params, f, indent=4)

print("âœ… Model trained and saved successfully!")
PYTHON_EOF
    
    - name: Run Model Performance Tests
      run: |
        echo "" >> report.md
        echo "## ðŸ§ª Model Performance Tests" >> report.md
        pytest tests/test_model_performance.py -v >> report.md 2>&1 || true
    
    - name: Generate SHAP Explanations
      run: |
        echo "" >> report.md
        echo "## ðŸ§  Model Explainability (SHAP)" >> report.md
        python src/generate_explanations.py >> report.md
    
    - name: Check Model Fairness
      run: |
        echo "" >> report.md
        echo "## âš–ï¸ Model Fairness Audit" >> report.md
        python src/check_fairness.py >> report.md
    
    - name: Check Data Drift
      run: |
        echo "" >> report.md
        echo "## ðŸŒŠ Data Drift Detection" >> report.md
        python src/check_drift_simple.py >> report.md
    
    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ml-artifacts
        path: artifacts/
        retention-days: 30
    
    - name: Create CML Report
      if: github.event_name == 'pull_request'
      env:
        REPO_TOKEN: ${{ secrets.CML_REPO_TOKEN }}
      run: |
        npm install -g @dvcorg/cml
        echo "### ðŸ“Š SHAP Feature Importance" >> report.md
        echo "![SHAP Summary](./artifacts/shap_summary.png)" >> report.md
        cml comment create report.md || echo "CML comment skipped"
    
    - name: Cleanup
      if: always()
      run: |
        rm -f gcp-key.json
        echo "ðŸ§¹ Cleaned up"
