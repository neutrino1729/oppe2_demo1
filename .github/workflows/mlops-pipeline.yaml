name: MLOps Fraud Detection Pipeline

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

permissions:
  contents: read
  pull-requests: write

jobs:
  data-validation-and-training:
    name: Data Validation & Model Training
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Authenticate to Google Cloud
      env:
        GCP_CREDENTIALS_B64: ${{ secrets.GCP_CREDENTIALS_B64 }}
      run: |
        echo "$GCP_CREDENTIALS_B64" | base64 -d > gcp-key.json
        echo "GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-key.json" >> $GITHUB_ENV
        python3 -c "import json; json.load(open('gcp-key.json'))" && echo "âœ“ Valid JSON"
    
    - name: Install Google Cloud SDK
      run: |
        echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
        curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
        sudo apt-get update && sudo apt-get install -y google-cloud-cli
    
    - name: Configure DVC and Pull Data
      run: |
        gcloud auth activate-service-account --key-file=gcp-key.json
        gcloud config set project theta-index-472515-d8
        dvc remote modify gcsremote credentialpath $(pwd)/gcp-key.json
        dvc pull -v
    
    - name: Run Data Validation Tests
      run: |
        echo "## ğŸ§ª Data Validation Tests" >> report.md
        echo "" >> report.md
        pytest tests/test_data_validation.py -v 2>&1 | tee -a report.md || true
    
    - name: Check for Data Poisoning
      id: poison_check
      run: |
        echo "" >> report.md
        echo "## ğŸ›¡ï¸ Data Poisoning Check" >> report.md
        echo "" >> report.md
        python src/check_poisoning.py --data-path data/transactions.csv 2>&1 | tee -a report.md
        
        # Extract suspicious count
        SUSPICIOUS_COUNT=$(grep "Suspicious labels found:" report.md | tail -1 | awk '{print $4}' | tr -d ',' || echo "0")
        echo "Suspicious count: $SUSPICIOUS_COUNT"
        echo "count=$SUSPICIOUS_COUNT" >> "$GITHUB_OUTPUT"
    
    - name: Validate Data Quality
      run: |
        SUSPICIOUS_COUNT="${{ steps.poison_check.outputs.count }}"
        if [ -z "$SUSPICIOUS_COUNT" ]; then SUSPICIOUS_COUNT=0; fi
        
        echo "Validating data quality with $SUSPICIOUS_COUNT suspicious labels"
        
        if [ "$SUSPICIOUS_COUNT" -gt 1000 ]; then
          echo "âŒ Too many suspicious labels detected: $SUSPICIOUS_COUNT"
          exit 1
        else
          echo "âœ… Data quality check passed (suspicious labels: $SUSPICIOUS_COUNT)"
        fi
    
    - name: Train Model (CI Mode - Direct CSV)
      run: |
        echo "" >> report.md
        echo "## ğŸš€ Model Training (CI Mode)" >> report.md
        echo "" >> report.md
        
        python << 'PYTHON_EOF' 2>&1 | tee -a report.md
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score
import joblib
import os
import json

print("=" * 70)
print("ğŸš€ TRAINING MODEL IN CI MODE")
print("=" * 70)

# Load data
print("\nğŸ“Š Loading data from CSV...")
df = pd.read_csv("data/transactions.csv")
print(f"   Loaded: {len(df):,} transactions")

# Prepare features
columns_to_drop = ['Class', 'Time']
if 'location' in df.columns:
    columns_to_drop.append('location')

X = df.drop(columns=columns_to_drop, errors='ignore')
y = df['Class']

print(f"\nğŸ“ˆ Dataset:")
print(f"   Features: {X.shape[1]}")
print(f"   Fraud rate: {y.mean():.4%}")

# Train-test split
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Model parameters
params = {
    'class_weight': 'balanced',
    'max_depth': 5,
    'min_samples_split': 100,
    'min_samples_leaf': 50,
    'random_state': 42
}

print(f"\nğŸ”§ Training Decision Tree...")
model = DecisionTreeClassifier(**params)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_val)
y_pred_proba = model.predict_proba(X_val)[:, 1]

# Metrics
f1 = f1_score(y_val, y_pred)
precision = precision_score(y_val, y_pred)
recall = recall_score(y_val, y_pred)
auc = roc_auc_score(y_val, y_pred_proba)

print(f"\nğŸ“Š Model Performance:")
print(f"   F1-Score:    {f1:.4f}")
print(f"   Precision:   {precision:.4f}")
print(f"   Recall:      {recall:.4f}")
print(f"   AUC-ROC:     {auc:.4f}")

# Save artifacts
os.makedirs("artifacts", exist_ok=True)
joblib.dump(model, "artifacts/model.pkl")

with open("artifacts/params.json", "w") as f:
    json.dump(params, f, indent=4)

print(f"\nğŸ’¾ Artifacts saved to artifacts/")
print("\n" + "=" * 70)
print("âœ… TRAINING COMPLETE!")
print("=" * 70)
PYTHON_EOF
    
    - name: Run Model Performance Tests
      run: |
        echo "" >> report.md
        echo "## ğŸ§ª Model Performance Tests" >> report.md
        echo "" >> report.md
        pytest tests/test_model_performance.py -v 2>&1 | tee -a report.md || true
    
    - name: Generate SHAP Explanations
      run: |
        echo "" >> report.md
        echo "## ğŸ§  Model Explainability (SHAP)" >> report.md
        echo "" >> report.md
        python src/generate_explanations.py 2>&1 | tee -a report.md
    
    - name: Check Model Fairness
      run: |
        echo "" >> report.md
        echo "## âš–ï¸ Model Fairness Audit" >> report.md
        echo "" >> report.md
        python src/check_fairness.py 2>&1 | tee -a report.md
    
    - name: Check Data Drift
      run: |
        echo "" >> report.md
        echo "## ğŸŒŠ Data Drift Detection" >> report.md
        echo "" >> report.md
        python src/check_drift_simple.py 2>&1 | tee -a report.md
    
    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ml-artifacts
        path: artifacts/
        retention-days: 30
    
    - name: Upload Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: pipeline-report
        path: report.md
        retention-days: 30
    
    - name: Display Report Summary
      if: always()
      run: |
        echo "ğŸ“Š Pipeline Report Summary"
        echo "=========================="
        grep -E "^##|âœ…|âŒ|âš ï¸" report.md || echo "Report generated"
    
    - name: Cleanup
      if: always()
      run: |
        rm -f gcp-key.json
        echo "ğŸ§¹ Cleanup complete"
